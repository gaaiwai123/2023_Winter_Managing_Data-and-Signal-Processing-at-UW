{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instruments: lead guitar, rhythm guitar, bass guitar, and drums\n",
        "Features: spectral features, rhythm features, timbre features, harmony features, lyrics and metadata"
      ],
      "metadata": {
        "id": "-YkmXbOOzrTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Music genre classification using spectral features"
      ],
      "metadata": {
        "id": "bHhBhuifzvvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Define the list of sub-genres to classify\n",
        "sub_genres = ['Instrumental Rock', 'Punk Rock', 'Electric Rock', 'Metal Rock', 'Soft Rock', 'Jazz Rock', 'House Rock', 'Experimental Rock']\n",
        "\n",
        "# Define the number of mel frequency bands to use\n",
        "n_mels = 128\n",
        "\n",
        "# Define the hop length (in samples)\n",
        "hop_length = 512\n",
        "\n",
        "# Define the window size (in samples)\n",
        "n_fft = 2048\n",
        "\n",
        "# Define the number of MFCCs to use\n",
        "n_mfcc = 20\n",
        "\n",
        "# Define a function to extract the features from an audio file\n",
        "def extract_features(filename):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(filename, sr=None)\n",
        "\n",
        "    # Extract the mel spectrogram\n",
        "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=n_mels, hop_length=hop_length, n_fft=n_fft)\n",
        "\n",
        "    # Convert the mel spectrogram to decibels (dB)\n",
        "    log_S = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "    # Extract the MFCCs\n",
        "    mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=n_mfcc)\n",
        "\n",
        "    # Compute the first-order and second-order differences of the MFCCs\n",
        "    delta1_mfcc = librosa.feature.delta(mfcc, order=1)\n",
        "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
        "\n",
        "    # Concatenate the MFCCs and their differences\n",
        "    features = np.concatenate((mfcc, delta1_mfcc, delta2_mfcc), axis=0)\n",
        "\n",
        "    # Return the extracted features\n",
        "    return features\n",
        "\n",
        "# Define a function to load the dataset and extract the features\n",
        "def load_dataset():\n",
        "    # Define the list of audio files\n",
        "    audio_files = []\n",
        "    for sub_genre in sub_genres:\n",
        "        sub_genre_dir = 'music/' + sub_genre\n",
        "        for filename in os.listdir(sub_genre_dir):\n",
        "            if filename.endswith('.mp3'):\n",
        "                audio_files.append((sub_genre, os.path.join(sub_genre_dir, filename)))\n",
        "\n",
        "    # Extract the features from the audio files\n",
        "    X = []\n",
        "    y = []\n",
        "    for sub_genre, filename in audio_files:\n",
        "        features = extract_features(filename)\n",
        "        X.append(features.T)\n",
        "        y.append(sub_genres.index(sub_genre))\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Return the dataset\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Load the dataset and extract the features\n",
        "X_train, X_test, y_train, y_test = load_dataset()\n",
        "\n",
        "# Train a SVM classifier using the extracted features\n",
        "clf = SVC(kernel='linear', C=1, gamma='scale')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred, target_names=sub_genres))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "88Gns7cUzsKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Music genre classification using rhythm features"
      ],
      "metadata": {
        "id": "GCSBSW9Sz7_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Define the list of sub-genres to classify\n",
        "sub_genres = ['Instrumental Rock', 'Punk Rock', 'Electric Rock', 'Metal Rock', 'Soft Rock', 'Jazz Rock', 'House Rock', 'Experimental Rock']\n",
        "\n",
        "# Define the hop length (in samples)\n",
        "hop_length = 512\n",
        "\n",
        "# Define the window size (in samples)\n",
        "n_fft = 2048\n",
        "\n",
        "# Define the number of MFCCs to use\n",
        "n_mfcc = 20\n",
        "\n",
        "# Define a function to extract the rhythm features from an audio file\n",
        "def extract_features(filename):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(filename, sr=None)\n",
        "\n",
        "    # Extract the onset envelope\n",
        "    onset_env = librosa.onset.onset_strength(y, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
        "\n",
        "    # Compute the tempo and beat positions\n",
        "    tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr, hop_length=hop_length)\n",
        "\n",
        "    # Extract the rhythm features\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_fft=n_fft, n_mfcc=n_mfcc)\n",
        "    rmse = librosa.feature.rmse(y=y, hop_length=hop_length, frame_length=n_fft)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
        "\n",
        "    # Compute the mean and standard deviation of the rhythm features\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc_std = np.std(mfcc, axis=1)\n",
        "    rmse_mean = np.mean(rmse)\n",
        "    rmse_std = np.std(rmse)\n",
        "    spectral_centroid_mean = np.mean(spectral_centroid)\n",
        "    spectral_centroid_std = np.std(spectral_centroid)\n",
        "    spectral_bandwidth_mean = np.mean(spectral_bandwidth)\n",
        "    spectral_bandwidth_std = np.std(spectral_bandwidth)\n",
        "    spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
        "    spectral_contrast_std = np.std(spectral_contrast, axis=1)\n",
        "    spectral_rolloff_mean = np.mean(spectral_rolloff)\n",
        "    spectral_rolloff_std = np.std(spectral_rolloff)\n",
        "\n",
        "    # Concatenate the rhythm features\n",
        "    features = np.concatenate((mfcc_mean, mfcc_std, [rmse_mean, rmse_std], [spectral_centroid_mean, spectral_centroid_std], [spectral_bandwidth_mean, spectral_bandwidth_std], spectral_contrast_mean, spectral_contrast_std, [spectral_rolloff_mean, spectral_rolloff_std]), axis=0)\n",
        "\n",
        "    # Return the extracted features\n",
        "    return features\n",
        "\n",
        "# Define a function to load the dataset and extract the rhythm features\n",
        "def load_dataset():\n",
        "    # Define the list of audio files\n",
        "    audio_files = []\n",
        "    for sub_genre in sub_gen\n"
      ],
      "metadata": {
        "id": "HyEcKZnJ0I2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting timbre features using Mel-Frequency Cepstral Coefficients (MFCC) from an audio file, and using them to train a machine learning model for music genre classification"
      ],
      "metadata": {
        "id": "NNxoTa2K0Ks8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the list of genres\n",
        "genres = ['Instrumental Rock', 'Punk Rock', 'Electric Rock', 'Metal Rock',\n",
        "          'Soft Rock', 'Jazz Rock', 'House Rock', 'Experimental Rock']\n",
        "\n",
        "# Define a function to extract MFCC features from an audio file\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20)\n",
        "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_path)\n",
        "        return None\n",
        "    return mfccs_mean\n",
        "\n",
        "# Create a dictionary to store the MFCC features and genre labels\n",
        "features = {}\n",
        "labels = {}\n",
        "\n",
        "# Iterate through each audio file in the dataset directory\n",
        "for genre in genres:\n",
        "    audio_files = os.listdir(f'dataset/{genre}')\n",
        "    for file in audio_files:\n",
        "        file_path = f'dataset/{genre}/{file}'\n",
        "        mfccs = extract_features(file_path)\n",
        "        if mfccs is not None:\n",
        "            features[file] = mfccs\n",
        "            labels[file] = genre\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = np.array(list(features.values()))\n",
        "y = np.array(list(labels.values()))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Train a machine learning model (here, we use a multi-layer perceptron classifier)\n",
        "model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the accuracy of the model on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "mIRxRXc70v69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads audio files from a directory named dataset, where each subdirectory is named after a genre and contains audio files belonging to that genre. The extract_features function uses Librosa to load an audio file, extract the MFCC features, and return their mean value. The features and genre labels are stored in a dictionary. The code then splits the data into training and testing sets, trains a multi-layer perceptron classifier on the training data, and evaluates its accuracy on the testing data."
      ],
      "metadata": {
        "id": "mygDwnxA099G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Music genre classification using harmony features"
      ],
      "metadata": {
        "id": "JdybXUlp0_O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the list of genres\n",
        "genres = ['Instrumental Rock', 'Punk Rock', 'Electric Rock', 'Metal Rock',\n",
        "          'Soft Rock', 'Jazz Rock', 'House Rock', 'Experimental Rock']\n",
        "\n",
        "# Define a function to extract chroma features from an audio file\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
        "        chroma = librosa.feature.chroma_stft(y=audio, sr=sr, n_chroma=12)\n",
        "        chroma_mean = np.mean(chroma.T, axis=0)\n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_path)\n",
        "        return None\n",
        "    return chroma_mean\n",
        "\n",
        "# Create a dictionary to store the chroma features and genre labels\n",
        "features = {}\n",
        "labels = {}\n",
        "\n",
        "# Iterate through each audio file in the dataset directory\n",
        "for genre in genres:\n",
        "    audio_files = os.listdir(f'dataset/{genre}')\n",
        "    for file in audio_files:\n",
        "        file_path = f'dataset/{genre}/{file}'\n",
        "        chroma = extract_features(file_path)\n",
        "        if chroma is not None:\n",
        "            features[file] = chroma\n",
        "            labels[file] = genre\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = np.array(list(features.values()))\n",
        "y = np.array(list(labels.values()))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Train a machine learning model (here, we use a multi-layer perceptron classifier)\n",
        "model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the accuracy of the model on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "fVL0wWTO1Wyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is similar to the previous sample code for timbre features, but it uses librosa.feature.chroma_stft to extract chroma features from each audio file. Chroma features are 12-dimensional vectors that represent the pitch class profiles of the music. The code then trains a machine learning model (again, a multi-layer perceptron classifier), and evaluates its accuracy on the testing data."
      ],
      "metadata": {
        "id": "Z1j4bypr1a-s"
      }
    }
  ]
}